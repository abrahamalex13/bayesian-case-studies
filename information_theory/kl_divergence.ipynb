{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# ensure kaggle api credentials available via .env\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import shutil\n",
    "import plotnine as p9\n",
    "import scipy.special as ssp\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "from information_theory.empirical_pmf import empirical_pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_STUDY = pathlib.Path(\"./information_theory\")\n",
    "DIR_PLOTS = DIR_STUDY / \"figures\"\n",
    "DIR_PLOTS.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NEEDS_DOWNLOADED = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_NEEDS_DOWNLOADED:\n",
    "\n",
    "    # expected workflow, though authentication issues persist\n",
    "    # api = KaggleApi()\n",
    "    # api.authenticate()\n",
    "    # api.competition_download_file(\n",
    "    #   \"dont-get-kicked\", \"training.csv\", path=\"./data/dont_get_kicked\"\n",
    "    # )\n",
    "\n",
    "    os.system('kaggle competitions download -c DontGetKicked')\n",
    "    shutil.unpack_archive(\"DontGetKicked.zip\", \"./data\")\n",
    "    os.remove(\"DontGetKicked.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./data/training.csv\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head().transpose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze: Discrete-Valued"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize (Intuition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Make'] = df_train[\"Make\"].fillna('NULL')\n",
    "df_test['Make'] = df_test[\"Make\"].fillna('NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_q = df_train['Make']\n",
    "n_q = df_train.shape[0]\n",
    "\n",
    "x_p = df_test['Make']\n",
    "n_p = df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = empirical_pmf(x_q.copy(), 10, include_other=True)\n",
    "q['series'] = 'Historical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = empirical_pmf(\n",
    "    x_p.copy(), 10, categories=list(q['Make']), include_other=True\n",
    "    )\n",
    "p['series'] = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_p_q = pd.concat([p, q], axis=0)\n",
    "compare_p_q = compare_p_q.rename(columns={'Make': 'bin'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggp = (\n",
    "    p9.ggplot(compare_p_q) + \n",
    "    p9.theme_minimal() + \n",
    "    p9.geom_col(p9.aes('bin', 'prb', fill='series'), position='dodge') + \n",
    "    p9.labs(y = \"Probability\", x = \"Make\", fill='',\n",
    "            title=(\n",
    "                \"Visually Insignificant Drift in Make Distribution, \\n\" +\n",
    "                \"Test vs Historical\"\n",
    "            ),\n",
    "            caption = (\n",
    "                \"Carvana data, from Kaggle. \\n\" + \n",
    "                \"# observations: historical, ~73,000; test, ~49,000.\"\n",
    "            )) + \n",
    "    p9.theme(legend_position='top', \n",
    "             legend_box_spacing=-.1,\n",
    "             plot_title=p9.element_text(margin={'b': 25})\n",
    "             ) + \n",
    "    p9.coord_flip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggp.save(DIR_PLOTS / \"drift_viz_overall.png\", units='in', dpi=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefer to align by index, in separate namespaces, for less data manipulation\n",
    "p = p.set_index('Make')\n",
    "q = q.set_index(\"Make\")\n",
    "p = p.loc[q.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm, selection-by-index does not drop any pmf elements\n",
    "p['prb'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_point = ssp.rel_entr(p[\"prb\"], q[\"prb\"]).sum()\n",
    "kl_div_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_draw_kl_divergence(x_q, nobs_test_set, nobs_lt_pool_other):\n",
    "    \"\"\"\n",
    "    Under the (null) condition that \n",
    "    a new observations test set generates from \n",
    "    the baseline population probability distribution q:\n",
    "    bootstrap sample one test set draw, then compute KL Divergence.\n",
    "\n",
    "    q is unknown and estimable: has generated observations `x_q`.\n",
    "    \"\"\"\n",
    "\n",
    "    var = x_q.name\n",
    "\n",
    "    q = empirical_pmf(\n",
    "        x_q, nobs_lt_pool_other, categories=[], include_other=True\n",
    "        )\n",
    "\n",
    "    x_p_sample = pd.Series(\n",
    "        np.random.choice(x_q, size=nobs_test_set, replace=True), name=var\n",
    "    )\n",
    "    p = empirical_pmf(\n",
    "        x_p_sample, nobs_lt_pool_other, \n",
    "        categories=list(q[var]), include_other=True\n",
    "        )\n",
    "    \n",
    "    p = p.set_index(var)\n",
    "    q = q.set_index(var)\n",
    "    p = p.loc[q.index]\n",
    "\n",
    "    kl_div = ssp.rel_entr(p[\"prb\"], q[\"prb\"]).sum()\n",
    "\n",
    "    return {'p': p, 'q': q, 'kl_divergence': kl_div}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sampling_distr_kl_divergence(\n",
    "        x_q, nobs_test_set, nobs_lt_pool_other, n_draws\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Under the (null) condition that \n",
    "    a new observations test set generates from \n",
    "    the baseline population probability distribution q:\n",
    "    simulate sampling distribution of KL Divergence value.\n",
    "\n",
    "    q is unknown and estimable: has generated observations `x_q`.\n",
    "\n",
    "    When a new observations test set does truly generate from\n",
    "    population probability distribution q, \n",
    "    KL Divergence sampling variation partly controlled by:\n",
    "        - Test set sample size (small sample size, wider variation)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    kl_div_draws = [\n",
    "        bootstrap_draw_kl_divergence(x_q, nobs_test_set, nobs_lt_pool_other)\n",
    "        for i in range(n_draws)\n",
    "    ]\n",
    "\n",
    "    kl_div_values = [x['kl_divergence'] for x in kl_div_draws]\n",
    "    idx_sort = np.argsort(kl_div_values)\n",
    "    kl_div_draws = [kl_div_draws[i] for i in idx_sort]\n",
    "\n",
    "    return kl_div_draws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLING_DISTR_DRAWS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_distr0 = bootstrap_sampling_distr_kl_divergence(\n",
    "    x_q.copy(), nobs_test_set=df_test.shape[0], \n",
    "    nobs_lt_pool_other=10, n_draws=N_SAMPLING_DISTR_DRAWS\n",
    "    )\n",
    "kl_div_distr = [x['kl_divergence'] for x in kl_div_distr0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_distr0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.array(kl_div_distr) > kl_div_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(kl_div_distr, q = [0.1, 0.25, 0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = kl_div_distr0[999]['p'].reset_index(drop=False)\n",
    "df_p['series'] = 'Extreme Test Draw (49K Obs) from Historical'\n",
    "\n",
    "df_q = kl_div_distr0[999]['q'].reset_index(drop=False)\n",
    "df_q['series'] = 'Historical'\n",
    "\n",
    "compare_p_q = pd.concat([df_p, df_q], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggp = (\n",
    "    p9.ggplot(compare_p_q) + \n",
    "    p9.theme_minimal() + \n",
    "    p9.geom_col(p9.aes('Make', 'prb', fill='series'), position='dodge') + \n",
    "    p9.labs(\n",
    "        y = \"Probability\", x = \"Make\", fill='',\n",
    "        title = (\n",
    "            \"If 49K New Test Observations Exactly Follow Historical, \\n\" +\n",
    "            \"Will Rarely Observe Drift More Extreme than Below\"\n",
    "        )\n",
    "    ) + \n",
    "    # ensure sufficient white space between title, legend, plot area\n",
    "    p9.theme(legend_position='top', \n",
    "             legend_box_spacing=-.1,\n",
    "             plot_title=p9.element_text(margin={'b': 25})\n",
    "             ) + \n",
    "    p9.coord_flip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggp.save(DIR_PLOTS / \"drift_viz_boot_naive.png\", units='in', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_distr0 = bootstrap_sampling_distr_kl_divergence(\n",
    "    x_q.copy(), nobs_test_set=100, \n",
    "    nobs_lt_pool_other=1, n_draws=N_SAMPLING_DISTR_DRAWS\n",
    "    )\n",
    "kl_div_distr = [x['kl_divergence'] for x in kl_div_distr0]\n",
    "\n",
    "sum(np.array(kl_div_distr) > kl_div_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = kl_div_distr0[950]['p'].reset_index(drop=False)\n",
    "df_p['series'] = 'Extreme Test Draw (100 Obs) from Historical'\n",
    "\n",
    "df_q = kl_div_distr0[950]['q'].reset_index(drop=False)\n",
    "df_q['series'] = 'Historical'\n",
    "\n",
    "compare_p_q = pd.concat([df_p, df_q], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggp = (\n",
    "    p9.ggplot(compare_p_q) + \n",
    "    p9.theme_minimal() + \n",
    "    p9.geom_col(p9.aes('Make', 'prb', fill='series'), position='dodge') + \n",
    "    p9.labs(\n",
    "        y = \"Probability\", x = \"Make\", fill='',\n",
    "        title = (\n",
    "            \"If 100 New Test Observations Exactly Follow Historical, \\n\" +\n",
    "            \"Will Rarely Observe Drift More Extreme than Below\"\n",
    "        )\n",
    "    ) + \n",
    "    # ensure sufficient white space between title, legend, plot area\n",
    "    p9.theme(legend_position='top', \n",
    "             legend_box_spacing=-.1,\n",
    "             plot_title=p9.element_text(margin={'b': 25})\n",
    "             ) + \n",
    "    p9.coord_flip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggp.save(DIR_PLOTS / \"drift_viz_boot_calibrated.png\", units='in', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit(\"End of main content.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplemental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze: Continuous-Valued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize (Intuition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['VehOdo'].isnull().sum())\n",
    "print(df_test['VehOdo'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_q = df_train['VehOdo']\n",
    "n_q = df_train.shape[0]\n",
    "\n",
    "x_p = df_test['VehOdo']\n",
    "n_p = df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BINS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.histogram(x_q, bins=N_BINS)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_histogram_bin_labels(hist_output):\n",
    "    \"\"\"\n",
    "    Intake np.histogram output directly, or subset bin edges.\n",
    "    Formatting tailored for magnitudes in 10,000s, 100,000s.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(hist_output) == tuple:\n",
    "        bin_edges = hist_output[1]\n",
    "    else:\n",
    "        bin_edges = hist_output\n",
    "\n",
    "    labels = [\n",
    "        str(i) + \": \" + \"[\" + f\"{bin_edges[i]:,.0f}\" + \", \" + \n",
    "        f\"{bin_edges[i+1]:,.0f}\" + \")\" \n",
    "        for i in range(bin_edges.shape[0]-1)\n",
    "        ]\n",
    "    # last bin closed on both sides\n",
    "    labels[-1] = labels[-1].replace(\")\", \"]\")\n",
    "    \n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels = format_histogram_bin_labels(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = pd.DataFrame({\n",
    "    'n': q[0],\n",
    "    'prb': q[0] / n_q,\n",
    "    'series': 'Historical'\n",
    "})\n",
    "df_q['bin'] = bin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.histogram(x_p, bins=q[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame({\n",
    "    'n': p[0],\n",
    "    'prb': p[0] / n_p,\n",
    "    'series': 'Test'\n",
    "})\n",
    "df_p['bin'] = bin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_p_q = pd.concat([df_q, df_p], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    p9.ggplot(compare_p_q) + \n",
    "    p9.theme_minimal() + \n",
    "    p9.geom_col(p9.aes('bin', 'prb', fill='series'), position='dodge') + \n",
    "    p9.labs(y = \"Probability\", x = \"Vehicle Mileage (Binned)\", fill='',\n",
    "            title=(\n",
    "                \"Vehicle Mileage Distribution Doesn't Meaningfully Drift, \\n\" +\n",
    "                \"Test vs Historical\"\n",
    "            ),\n",
    "            caption = (\n",
    "                \"Carvana data, from Kaggle. \\n\" + \n",
    "                \"# observations: \\nhistorical, ~73,000; \\ntest, ~49,000.\"\n",
    "            )) + \n",
    "    p9.theme(\n",
    "        axis_text_x=p9.element_text(angle=45), \n",
    "        plot_caption=p9.element_text(margin={'r': -100, 't': 25}),\n",
    "        )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_point = ssp.rel_entr(p[0] / n_p, q[0] / n_q).sum()\n",
    "kl_div_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_draw_kl_divergence(x_q, n_bins, nobs_test_set):\n",
    "    \"\"\"\n",
    "    Under the (null) condition that \n",
    "    a new observations test set generates from \n",
    "    the baseline population probability distribution q:\n",
    "    bootstrap sample one test set draw, then compute KL Divergence.\n",
    "\n",
    "    q is unknown and estimable:\n",
    "        - Has generated observations `x_q`\n",
    "        - Estimated by discrete pmf with `n_bins`\n",
    "    \"\"\"\n",
    "\n",
    "    q_hist = np.histogram(x_q, bins=n_bins)\n",
    "    n_q = q_hist[0].sum()\n",
    "\n",
    "    x_p_sample = np.random.choice(x_q, size=nobs_test_set, replace=True)\n",
    "    p_hist = np.histogram(x_p_sample, bins=q_hist[1])\n",
    "\n",
    "    q_hat = q_hist[0] / n_q\n",
    "    p_hat = p_hist[0] / nobs_test_set\n",
    "\n",
    "    kl_div = ssp.rel_entr(p_hat, q_hat).sum()\n",
    "\n",
    "    out = {\n",
    "        'p': p_hat, 'n_p': nobs_test_set, \n",
    "        'q': q_hat, 'bins': q_hist[1], \n",
    "        'kl_divergence': kl_div\n",
    "        }\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sampling_distr_kl_divergence(x_q, n_bins, nobs_test_set, n_draws):\n",
    "    \"\"\"\n",
    "    Under the (null) condition that \n",
    "    a new observations test set generates from \n",
    "    the baseline population probability distribution q:\n",
    "    simulate sampling distribution of KL Divergence value.\n",
    "\n",
    "    q is unknown and estimable:\n",
    "        - Has generated observations `x_q`\n",
    "        - Estimated by discrete pmf with `n_bins`\n",
    "\n",
    "    When a new observations test set does truly generate from\n",
    "    population probability distribution q, \n",
    "    KL Divergence sampling variation partly controlled by:\n",
    "        - Test set sample size (small sample size, wider variation)\n",
    "        - Probability distribution q estimate precision \n",
    "        (more discretized bins, wider variation) \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    kl_div_draws = [\n",
    "        bootstrap_draw_kl_divergence(x_q, n_bins, nobs_test_set)\n",
    "        for i in range(n_draws)\n",
    "    ]\n",
    "\n",
    "    kl_div_values = [x['kl_divergence'] for x in kl_div_draws]\n",
    "    idx_sort = np.argsort(kl_div_values)\n",
    "    kl_div_draws = [kl_div_draws[i] for i in idx_sort]\n",
    "\n",
    "    return kl_div_draws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLING_DISTR_DRAWS = 1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_distr0 = bootstrap_sampling_distr_kl_divergence(\n",
    "    x_q, N_BINS, df_test.shape[0], N_SAMPLING_DISTR_DRAWS\n",
    "    )\n",
    "kl_div_distr = [x['kl_divergence'] for x in kl_div_distr0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_distr0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.array(kl_div_distr) > kl_div_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(kl_div_distr, q = [0.1, 0.25, 0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta = [kl_div_distr[i] - kl_div_distr[i-1] for i in range(1, len(kl_div_distr))]\n",
    "# sum(np.array(delta) < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame({\n",
    "    'prb': kl_div_distr0[999]['p'], 'series': 'Extreme Test Draw (49K Obs) from Historical'\n",
    "    })\n",
    "df_p['bin'] = format_histogram_bin_labels(kl_div_distr0[0]['bins'])\n",
    "\n",
    "df_q = pd.DataFrame({'prb': kl_div_distr0[999]['q'], 'series': 'Historical'})\n",
    "df_q['bin'] = format_histogram_bin_labels(kl_div_distr0[1]['bins'])\n",
    "\n",
    "compare_p_q = pd.concat([df_p, df_q], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    p9.ggplot(compare_p_q) + \n",
    "    p9.theme_minimal() + \n",
    "    p9.geom_col(p9.aes('bin', 'prb', fill='series'), position='dodge') + \n",
    "    p9.labs(\n",
    "        y = \"Probability\", x = \"Vehicle Mileage (Binned)\", fill='',\n",
    "        title = (\n",
    "            \"If 49K New Test Observations Follow Historical Distribution, \\n\" +\n",
    "            \"Will Rarely Observe Drift More Extreme than Below\"\n",
    "        )\n",
    "    ) + \n",
    "    # ensure sufficient white space between title, legend, plot area\n",
    "    p9.theme(legend_position='top', \n",
    "             legend_box_spacing=-.1,\n",
    "             plot_title=p9.element_text(margin={'b': 25}),\n",
    "             axis_text_x=p9.element_text(angle=45))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_distr0 = bootstrap_sampling_distr_kl_divergence(\n",
    "    x_q, N_BINS, 100, N_SAMPLING_DISTR_DRAWS\n",
    "    )\n",
    "kl_div_distr = [x['kl_divergence'] for x in kl_div_distr0]\n",
    "\n",
    "sum(np.array(kl_div_distr) > kl_div_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame({\n",
    "    'prb': kl_div_distr0[999]['p'], 'series': 'Extreme Test Draw (100 Obs) from Historical'\n",
    "    })\n",
    "df_p['bin'] = format_histogram_bin_labels(kl_div_distr0[0]['bins'])\n",
    "\n",
    "df_q = pd.DataFrame({'prb': kl_div_distr0[999]['q'], 'series': 'Historical'})\n",
    "df_q['bin'] = format_histogram_bin_labels(kl_div_distr0[1]['bins'])\n",
    "\n",
    "compare_p_q = pd.concat([df_p, df_q], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    p9.ggplot(compare_p_q) + \n",
    "    p9.theme_minimal() + \n",
    "    p9.geom_col(p9.aes('bin', 'prb', fill='series'), position='dodge') + \n",
    "    p9.labs(\n",
    "        y = \"Probability\", x = \"Vehicle Mileage (Binned)\", fill='',\n",
    "        title = (\n",
    "            \"If 100 New Test Observations Follow Historical Distribution, \\n\" +\n",
    "            \"Will Rarely Observe Drift More Extreme than Below\"\n",
    "        )\n",
    "    ) + \n",
    "    # ensure sufficient white space between title, legend, plot area\n",
    "    p9.theme(legend_position='top', \n",
    "             legend_box_spacing=-.1,\n",
    "             plot_title=p9.element_text(margin={'b': 25}),\n",
    "             axis_text_x=p9.element_text(angle=45))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
