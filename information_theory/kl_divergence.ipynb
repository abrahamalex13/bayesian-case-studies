{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# ensure kaggle api credentials available via .env\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import shutil\n",
    "import plotnine as p9\n",
    "import scipy.special as ssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NEEDS_DOWNLOADED = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_NEEDS_DOWNLOADED:\n",
    "\n",
    "    # expected workflow, though authentication issues persist\n",
    "    # api = KaggleApi()\n",
    "    # api.authenticate()\n",
    "    # api.competition_download_file(\"dont-get-kicked\", \"training.csv\", path=\"./data/dont_get_kicked\")\n",
    "\n",
    "    os.system('kaggle competitions download -c DontGetKicked')\n",
    "    shutil.unpack_archive(\"DontGetKicked.zip\", \"./data\")\n",
    "    os.remove(\"DontGetKicked.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./data/training.csv\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head().transpose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Intuition through Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BINS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_q = df_train['VehOdo']\n",
    "n_q = df_train.shape[0]\n",
    "\n",
    "x_p = df_test['VehOdo']\n",
    "n_p = df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.histogram(x_q, bins=N_BINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = pd.DataFrame({\n",
    "    'n': q[0],\n",
    "    'prb': q[0] / n_q,\n",
    "    'series': 'Train'\n",
    "})\n",
    "df_q['bin'] = df_q.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.histogram(x_p, bins=q[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame({\n",
    "    'n': p[0],\n",
    "    'prb': p[0] / n_p,\n",
    "    'series': 'Test'\n",
    "})\n",
    "df_p['bin'] = df_p.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_p_q = pd.concat([df_q, df_p], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    p9.ggplot(compare_p_q) + \n",
    "    p9.theme_minimal() + \n",
    "    p9.geom_col(p9.aes('bin', 'prb', fill='series'), position='dodge') + \n",
    "    p9.labs(fill='')\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLING_DISTR_DRAWS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_point = ssp.rel_entr(p[0] / n_p, q[0] / n_q).sum()\n",
    "kl_div_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_draw_kl_divergence(x_q, n_bins, nobs_test_set):\n",
    "    \"\"\"\n",
    "    Under the (null) condition that \n",
    "    a new observations test set generates from \n",
    "    the baseline population probability distribution q:\n",
    "    bootstrap sample one test set draw, then compute KL Divergence.\n",
    "\n",
    "    q characteristics:\n",
    "        - Has generated observations `x_q`\n",
    "        - Estimated by discrete pmf with `n_bins`\n",
    "    \"\"\"\n",
    "\n",
    "    q_hist = np.histogram(x_q, bins=n_bins)\n",
    "    n_q = q_hist[0].sum()\n",
    "\n",
    "    x_p_sample = np.random.choice(x_q, size=nobs_test_set, replace=True)\n",
    "    p_hist = np.histogram(x_p_sample, bins=q_hist[1])\n",
    "\n",
    "    q_hat = q_hist[0] / n_q\n",
    "    p_hat = p_hist[0] / nobs_test_set\n",
    "\n",
    "    kl_div = ssp.rel_entr(p_hat, q_hat).sum()\n",
    "\n",
    "    out = {'p': p_hat, 'n_p': nobs_test_set, 'q': q_hat, 'kl_divergence': kl_div}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sampling_distr_kl_divergence(x_q, n_bins, nobs_test_set, n_draws):\n",
    "    \"\"\"\n",
    "    Under the (null) condition that \n",
    "    a new observations test set generates from \n",
    "    the baseline population probability distribution q:\n",
    "    simulate sampling distribution of KL Divergence value.\n",
    "\n",
    "    q characteristics:\n",
    "        - Has generated observations `x_q`\n",
    "        - Estimated by discrete pmf with `n_bins`\n",
    "\n",
    "    When a new observations test set does truly generate from\n",
    "    population probability distribution q, \n",
    "    KL Divergence sampling variation partly controlled by:\n",
    "        - Test set sample size (small sample size, wider variation)\n",
    "        - Probability distribution q estimate precision \n",
    "        (more discretized bins, wider variation) \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    kl_div_draws = [\n",
    "        bootstrap_draw_kl_divergence(x_q, n_bins, nobs_test_set)\n",
    "        for i in range(n_draws)\n",
    "    ]\n",
    "\n",
    "    kl_div_values = [x['kl_divergence'] for x in kl_div_draws]\n",
    "    idx_sort = np.argsort(kl_div_values)\n",
    "    kl_div_draws = [kl_div_draws[i] for i in idx_sort]\n",
    "\n",
    "    return kl_div_draws\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_distr0 = bootstrap_sampling_distr_kl_divergence(x_q, N_BINS, df_test.shape[0], N_SAMPLING_DISTR_DRAWS)\n",
    "kl_div_distr = [x['kl_divergence'] for x in kl_div_distr0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.array(kl_div_distr) > kl_div_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(kl_div_distr, q = [0.1, 0.25, 0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta = [kl_div_distr[i] - kl_div_distr[i-1] for i in range(1, len(kl_div_distr))]\n",
    "# sum(np.array(delta) < 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_distr0 = bootstrap_sampling_distr_kl_divergence(x_q, N_BINS, 100, N_SAMPLING_DISTR_DRAWS)\n",
    "kl_div_distr = [x['kl_divergence'] for x in kl_div_distr0]\n",
    "\n",
    "sum(np.array(kl_div_distr) > kl_div_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame({'prb': kl_div_distr0[999]['p'], 'series': 'Test'})\n",
    "df_p['bin'] = df_p.index.values\n",
    "\n",
    "df_q = pd.DataFrame({'prb': kl_div_distr0[999]['q'], 'series': 'Train'})\n",
    "df_q['bin'] = df_q.index.values\n",
    "\n",
    "compare_p_q = pd.concat([df_p, df_q], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    p9.ggplot(compare_p_q) + \n",
    "    p9.theme_minimal() + \n",
    "    p9.geom_col(p9.aes('bin', 'prb', fill='series'), position='dodge') + \n",
    "    p9.labs(fill='')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_distr0 = bootstrap_sampling_distr_kl_divergence(x_q, N_BINS, 1000, N_SAMPLING_DISTR_DRAWS)\n",
    "kl_div_distr = [x['kl_divergence'] for x in kl_div_distr0]\n",
    "\n",
    "sum(np.array(kl_div_distr) > kl_div_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame({'prb': kl_div_distr0[999]['p'], 'series': 'Test'})\n",
    "df_p['bin'] = df_p.index.values\n",
    "\n",
    "df_q = pd.DataFrame({'prb': kl_div_distr0[999]['q'], 'series': 'Train'})\n",
    "df_q['bin'] = df_q.index.values\n",
    "\n",
    "compare_p_q = pd.concat([df_p, df_q], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    p9.ggplot(compare_p_q) + \n",
    "    p9.theme_minimal() + \n",
    "    p9.geom_col(p9.aes('bin', 'prb', fill='series'), position='dodge') + \n",
    "    p9.labs(fill='')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_distr0 = bootstrap_sampling_distr_kl_divergence(x_q, N_BINS, 10000, N_SAMPLING_DISTR_DRAWS)\n",
    "kl_div_distr = [x['kl_divergence'] for x in kl_div_distr0]\n",
    "\n",
    "sum(np.array(kl_div_distr) > kl_div_point)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
