---
title: "The Taxicab Problem"
date: "11/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center')

do_main <- TRUE
if (do_main) {
  source("main.R")
}
viz_priors <- readRDS("viz_priors.rds")
```

# Problem Statement

"Suppose you arrive in a new city and see a taxi numbered 100. How many taxis are there in this city?"^[I find this question in Kevin Murphy's _Machine Learning: A Probabilistic Perspective_. A great read!] Taxis are numbered 0, 1, 2, 3, ..., up to the last taxi.


# A Classical Approach

You already have intuition about how to proceed. The likelihood of what you observed -- taxicab #100 -- depends on how many taxis there are in total. Your estimate of total taxi count should somehow elevate the likelihood of what you observed.

A classical approach: estimate a total taxi count which _maximizes_ the likelihood of what you observed.^["Maximum Likelihood Estimation" is a fundamental method in statistics.] An estimate of 101 follows. (Recall: numbering started at zero.) Why? Assuming the city has 101 taxicabs, the likelihood of observing taxicab #100 equals 1/101, or about 1%. Estimate any higher number of taxicabs, and this probability necessarily decreases.

However, this estimate is not exactly satisfying. This "optimal" estimate follows from a _narrowly-defined_ framework, which must be scrutinized. Then, a fundamental question arises: what if we simply observed an event with less-than-maximum likelihood? This feels entirely possible -- our lives are full of relatively surprising events. 

Estimation error might decrease under a different statistical approach. How?
Suppose that, _on average_, the classical approach correctly estimates total taxi count.
Then, consider a useful definition of error: the estimate's **variance**
(about the true value). **The path to error reduction becomes clear: 
decrease estimate variance, without too much compromising average accuracy.**


# A Bayesian Approach

Consider an estimation approach partly _anchored_ to knowledge 
beyond what's immediately observed. In this approach,
we articulate and update "strength of belief" in possible values 
for total taxi count^[This estimation approach follows Bayes' Theorem, another fundamental statement in statistics.]: 

1. Specify prior knowledge about total taxi count, and then 
2. Update that assessment, given what we observed (taxicab #100).

## Specify Prior Knowledge About Total Taxi Count

How might we specify prior knowledge about total taxi count? We'll quantify our "strength of belief" in possible values. 

- First we'll identify that complete set of possible values. 
- Then, we'll assign a weight to each possible value -- higher weight signifies stronger belief. The weights may be generated by an explicit probability formula^[In the lingo, probability distribution.], for simpler calculations later. 

Imagine a few scenarios for prior knowledge^[These prior knowledge scenarios come from one probability distribution _family_, the Pareto.]:

```{r}
  viz_priors
```


## Update Belief About Total Taxi Count, Given Observed Evidence



